{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 2s 47ms/step - loss: 0.6931\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.69312, saving model to weights-improvement-01-0.6931-bigger.hdf5\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6893\n",
      "\n",
      "Epoch 00002: loss improved from 0.69312 to 0.68929, saving model to weights-improvement-02-0.6893-bigger.hdf5\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.6852\n",
      "\n",
      "Epoch 00003: loss improved from 0.68929 to 0.68520, saving model to weights-improvement-03-0.6852-bigger.hdf5\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 0s 728us/step - loss: 0.6810\n",
      "\n",
      "Epoch 00004: loss improved from 0.68520 to 0.68101, saving model to weights-improvement-04-0.6810-bigger.hdf5\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6768\n",
      "\n",
      "Epoch 00005: loss improved from 0.68101 to 0.67681, saving model to weights-improvement-05-0.6768-bigger.hdf5\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6719\n",
      "\n",
      "Epoch 00006: loss improved from 0.67681 to 0.67190, saving model to weights-improvement-06-0.6719-bigger.hdf5\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.6671\n",
      "\n",
      "Epoch 00007: loss improved from 0.67190 to 0.66707, saving model to weights-improvement-07-0.6671-bigger.hdf5\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6610\n",
      "\n",
      "Epoch 00008: loss improved from 0.66707 to 0.66101, saving model to weights-improvement-08-0.6610-bigger.hdf5\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 0s 820us/step - loss: 0.6547\n",
      "\n",
      "Epoch 00009: loss improved from 0.66101 to 0.65466, saving model to weights-improvement-09-0.6547-bigger.hdf5\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 0s 888us/step - loss: 0.6493\n",
      "\n",
      "Epoch 00010: loss improved from 0.65466 to 0.64931, saving model to weights-improvement-10-0.6493-bigger.hdf5\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 0s 925us/step - loss: 0.6424\n",
      "\n",
      "Epoch 00011: loss improved from 0.64931 to 0.64244, saving model to weights-improvement-11-0.6424-bigger.hdf5\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 0s 735us/step - loss: 0.6340\n",
      "\n",
      "Epoch 00012: loss improved from 0.64244 to 0.63395, saving model to weights-improvement-12-0.6340-bigger.hdf5\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.6271\n",
      "\n",
      "Epoch 00013: loss improved from 0.63395 to 0.62715, saving model to weights-improvement-13-0.6271-bigger.hdf5\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6180\n",
      "\n",
      "Epoch 00014: loss improved from 0.62715 to 0.61804, saving model to weights-improvement-14-0.6180-bigger.hdf5\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 0s 844us/step - loss: 0.6083\n",
      "\n",
      "Epoch 00015: loss improved from 0.61804 to 0.60826, saving model to weights-improvement-15-0.6083-bigger.hdf5\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 0s 965us/step - loss: 0.5987\n",
      "\n",
      "Epoch 00016: loss improved from 0.60826 to 0.59865, saving model to weights-improvement-16-0.5987-bigger.hdf5\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5889\n",
      "\n",
      "Epoch 00017: loss improved from 0.59865 to 0.58888, saving model to weights-improvement-17-0.5889-bigger.hdf5\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5794\n",
      "\n",
      "Epoch 00018: loss improved from 0.58888 to 0.57936, saving model to weights-improvement-18-0.5794-bigger.hdf5\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 0s 992us/step - loss: 0.5676\n",
      "\n",
      "Epoch 00019: loss improved from 0.57936 to 0.56764, saving model to weights-improvement-19-0.5676-bigger.hdf5\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5555\n",
      "\n",
      "Epoch 00020: loss improved from 0.56764 to 0.55552, saving model to weights-improvement-20-0.5555-bigger.hdf5\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5433\n",
      "\n",
      "Epoch 00021: loss improved from 0.55552 to 0.54327, saving model to weights-improvement-21-0.5433-bigger.hdf5\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 0s 965us/step - loss: 0.5283\n",
      "\n",
      "Epoch 00022: loss improved from 0.54327 to 0.52827, saving model to weights-improvement-22-0.5283-bigger.hdf5\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5152\n",
      "\n",
      "Epoch 00023: loss improved from 0.52827 to 0.51521, saving model to weights-improvement-23-0.5152-bigger.hdf5\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5024\n",
      "\n",
      "Epoch 00024: loss improved from 0.51521 to 0.50242, saving model to weights-improvement-24-0.5024-bigger.hdf5\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 0s 974us/step - loss: 0.4893\n",
      "\n",
      "Epoch 00025: loss improved from 0.50242 to 0.48928, saving model to weights-improvement-25-0.4893-bigger.hdf5\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4737\n",
      "\n",
      "Epoch 00026: loss improved from 0.48928 to 0.47372, saving model to weights-improvement-26-0.4737-bigger.hdf5\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4571\n",
      "\n",
      "Epoch 00027: loss improved from 0.47372 to 0.45705, saving model to weights-improvement-27-0.4571-bigger.hdf5\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4455\n",
      "\n",
      "Epoch 00028: loss improved from 0.45705 to 0.44555, saving model to weights-improvement-28-0.4455-bigger.hdf5\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 0s 999us/step - loss: 0.4308\n",
      "\n",
      "Epoch 00029: loss improved from 0.44555 to 0.43079, saving model to weights-improvement-29-0.4308-bigger.hdf5\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.4132\n",
      "\n",
      "Epoch 00030: loss improved from 0.43079 to 0.41316, saving model to weights-improvement-30-0.4132-bigger.hdf5\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.4038\n",
      "\n",
      "Epoch 00031: loss improved from 0.41316 to 0.40383, saving model to weights-improvement-31-0.4038-bigger.hdf5\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3869\n",
      "\n",
      "Epoch 00032: loss improved from 0.40383 to 0.38685, saving model to weights-improvement-32-0.3869-bigger.hdf5\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 0s 733us/step - loss: 0.3700\n",
      "\n",
      "Epoch 00033: loss improved from 0.38685 to 0.37002, saving model to weights-improvement-33-0.3700-bigger.hdf5\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.3625\n",
      "\n",
      "Epoch 00034: loss improved from 0.37002 to 0.36254, saving model to weights-improvement-34-0.3625-bigger.hdf5\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.3500\n",
      "\n",
      "Epoch 00035: loss improved from 0.36254 to 0.35000, saving model to weights-improvement-35-0.3500-bigger.hdf5\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3410\n",
      "\n",
      "Epoch 00036: loss improved from 0.35000 to 0.34104, saving model to weights-improvement-36-0.3410-bigger.hdf5\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3288\n",
      "\n",
      "Epoch 00037: loss improved from 0.34104 to 0.32877, saving model to weights-improvement-37-0.3288-bigger.hdf5\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3259\n",
      "\n",
      "Epoch 00038: loss improved from 0.32877 to 0.32585, saving model to weights-improvement-38-0.3259-bigger.hdf5\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3105\n",
      "\n",
      "Epoch 00039: loss improved from 0.32585 to 0.31045, saving model to weights-improvement-39-0.3105-bigger.hdf5\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 0s 825us/step - loss: 0.3040\n",
      "\n",
      "Epoch 00040: loss improved from 0.31045 to 0.30397, saving model to weights-improvement-40-0.3040-bigger.hdf5\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.3029\n",
      "\n",
      "Epoch 00041: loss improved from 0.30397 to 0.30289, saving model to weights-improvement-41-0.3029-bigger.hdf5\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 0s 773us/step - loss: 0.2981\n",
      "\n",
      "Epoch 00042: loss improved from 0.30289 to 0.29806, saving model to weights-improvement-42-0.2981-bigger.hdf5\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.2955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00043: loss improved from 0.29806 to 0.29553, saving model to weights-improvement-43-0.2955-bigger.hdf5\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 0s 851us/step - loss: 0.2879\n",
      "\n",
      "Epoch 00044: loss improved from 0.29553 to 0.28786, saving model to weights-improvement-44-0.2879-bigger.hdf5\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 0s 723us/step - loss: 0.2867\n",
      "\n",
      "Epoch 00045: loss improved from 0.28786 to 0.28669, saving model to weights-improvement-45-0.2867-bigger.hdf5\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2799\n",
      "\n",
      "Epoch 00046: loss improved from 0.28669 to 0.27995, saving model to weights-improvement-46-0.2799-bigger.hdf5\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2755\n",
      "\n",
      "Epoch 00047: loss improved from 0.27995 to 0.27549, saving model to weights-improvement-47-0.2755-bigger.hdf5\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2812\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.27549\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2708\n",
      "\n",
      "Epoch 00049: loss improved from 0.27549 to 0.27081, saving model to weights-improvement-49-0.2708-bigger.hdf5\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 0s 717us/step - loss: 0.2737\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.27081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181ca8e048>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Larger LSTM Network to Generate Text for Alice in Wonderland\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "# load ascii text and covert to lowercase\n",
    "filename = \"wonderland.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()\n",
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "# print(\"Total Characters: \", n_chars)\n",
    "# print(\"Total Vocab: \", n_vocab)\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 1\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "# print \"Total Patterns: \", n_patterns\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "print(dataY)\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa"
     ]
    }
   ],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "# print \"Seed:\"\n",
    "# print \"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\"\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "# print \"\\nDone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
